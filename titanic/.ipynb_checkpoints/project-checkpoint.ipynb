{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMJQuest\n",
    "## Applying machine learning for temporomandibular disorders diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All needed resources to execute this code, as well as generated documentation,  are available in https://github.com/manolomaldonado/tmjquest-ml. It is divided into 3 main sections that must be executed sequentially.\n",
    " - Data exploration\n",
    " - Unsupervised learning for dimensionality reduction\n",
    " - Prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import pairwise_distances_argmin, silhouette_score, accuracy_score, confusion_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients dataset has 681 samples with 401 features each.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    dataset = pd.read_csv(\"data/tmd_data.csv\")\n",
    "    print(\"Patients dataset has {} samples with {} features each.\".format(*dataset.shape))\n",
    "except Exception as e:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing? \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a first look to dataset. We are interested in knowing number, type, range of values and empty parameters in order to take further decisions about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cefaleas/TMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DM. Referido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DDSRSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DDCRCBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDSRCLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DDCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mialgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mialgia Local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DDCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Artralgia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  Q392  Q393  Q394  Q395  Q396  \\\n",
       "0   1   1   0   1   0   1   1   0   1    2  ...     0     0     1     0     1   \n",
       "1   1   0   1   1   1   1   1   1   1    6  ...     1     0     1     0     1   \n",
       "2   0   0   0   0   0   0   0   1   0    3  ...     1     1     1     1     0   \n",
       "3   0   0   0   1   0   0   0   0   1    4  ...     1     0     1     0     1   \n",
       "4   1   0   0   0   1   1   0   0   0    5  ...     1     0     0     1     1   \n",
       "5   0   0   0   0   0   0   0   0   0    2  ...     1     1     0     0     0   \n",
       "6   1   1   1   1   1   1   1   1   1    3  ...     0     0     0     1     1   \n",
       "7   1   0   1   1   1   1   1   1   1    2  ...     1     0     0     1     1   \n",
       "8   0   0   0   0   0   0   0   0   1    7  ...     1     0     1     1     0   \n",
       "9   1   0   1   1   1   1   1   1   1    3  ...     0     0     0     0     1   \n",
       "\n",
       "   Q397  Q398  Q399  Q400          Label  \n",
       "0     0     1     0     0   Cefaleas/TMD  \n",
       "1     0     1     0     0   DM. Referido  \n",
       "2     1     0     0     0        DDSRSLA  \n",
       "3     1     1     0     0        DDCRCBI  \n",
       "4     1     0     0     1        DDSRCLA  \n",
       "5     1     1     0     0           DDCR  \n",
       "6     1     0     0     0        Mialgia  \n",
       "7     1     0     0     1  Mialgia Local  \n",
       "8     0     1     1     0           DDCR  \n",
       "9     0     1     0     0      Artralgia  \n",
       "\n",
       "[10 rows x 401 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>681.00000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.63583</td>\n",
       "      <td>0.349486</td>\n",
       "      <td>0.355360</td>\n",
       "      <td>0.555066</td>\n",
       "      <td>0.509545</td>\n",
       "      <td>0.538913</td>\n",
       "      <td>0.506608</td>\n",
       "      <td>0.475771</td>\n",
       "      <td>0.725404</td>\n",
       "      <td>3.809104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646109</td>\n",
       "      <td>0.509545</td>\n",
       "      <td>0.484581</td>\n",
       "      <td>0.550661</td>\n",
       "      <td>0.618209</td>\n",
       "      <td>0.609398</td>\n",
       "      <td>0.534508</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.292217</td>\n",
       "      <td>0.240822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.48155</td>\n",
       "      <td>0.477158</td>\n",
       "      <td>0.478974</td>\n",
       "      <td>0.497324</td>\n",
       "      <td>0.500276</td>\n",
       "      <td>0.498850</td>\n",
       "      <td>0.500324</td>\n",
       "      <td>0.499780</td>\n",
       "      <td>0.446639</td>\n",
       "      <td>1.945275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478527</td>\n",
       "      <td>0.500276</td>\n",
       "      <td>0.500130</td>\n",
       "      <td>0.497792</td>\n",
       "      <td>0.486183</td>\n",
       "      <td>0.488244</td>\n",
       "      <td>0.499174</td>\n",
       "      <td>0.499974</td>\n",
       "      <td>0.455116</td>\n",
       "      <td>0.427897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q1          Q2          Q3          Q4          Q5          Q6  \\\n",
       "count  681.00000  681.000000  681.000000  681.000000  681.000000  681.000000   \n",
       "mean     0.63583    0.349486    0.355360    0.555066    0.509545    0.538913   \n",
       "std      0.48155    0.477158    0.478974    0.497324    0.500276    0.498850   \n",
       "min      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.00000    0.000000    0.000000    1.000000    1.000000    1.000000   \n",
       "75%      1.00000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.00000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               Q7          Q8          Q9         Q10  ...        Q391  \\\n",
       "count  681.000000  681.000000  681.000000  681.000000  ...  681.000000   \n",
       "mean     0.506608    0.475771    0.725404    3.809104  ...    0.646109   \n",
       "std      0.500324    0.499780    0.446639    1.945275  ...    0.478527   \n",
       "min      0.000000    0.000000    0.000000    1.000000  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    2.000000  ...    0.000000   \n",
       "50%      1.000000    0.000000    1.000000    4.000000  ...    1.000000   \n",
       "75%      1.000000    1.000000    1.000000    6.000000  ...    1.000000   \n",
       "max      1.000000    1.000000    1.000000    7.000000  ...    1.000000   \n",
       "\n",
       "             Q392        Q393        Q394        Q395        Q396        Q397  \\\n",
       "count  681.000000  681.000000  681.000000  681.000000  681.000000  681.000000   \n",
       "mean     0.509545    0.484581    0.550661    0.618209    0.609398    0.534508   \n",
       "std      0.500276    0.500130    0.497792    0.486183    0.488244    0.499174   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             Q398        Q399        Q400  \n",
       "count  681.000000  681.000000  681.000000  \n",
       "mean     0.480176    0.292217    0.240822  \n",
       "std      0.499974    0.455116    0.427897  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      1.000000    1.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 400 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty columns  ['Q74', 'Q76', 'Q78', 'Q80', 'Q82', 'Q84', 'Q86', 'Q88', 'Q90', 'Q92', 'Q94', 'Q96', 'Q100', 'Q101', 'Q102']\n",
      "Only one different value columns  ['Q350', 'Q353', 'Q356', 'Q359', 'Q362', 'Q365', 'Q368', 'Q371']\n",
      "Int value params ['Q10', 'Q19', 'Q49', 'Q50', 'Q51', 'Q103', 'Q104', 'Q105', 'Q106', 'Q107', 'Q108', 'Q114', 'Q115', 'Q116', 'Q160', 'Q161', 'Q162']\n"
     ]
    }
   ],
   "source": [
    "empty_columns = dataset.columns[dataset.isnull().all()].tolist()\n",
    "one_value_columns = dataset.columns[dataset.nunique()==1].tolist()\n",
    "multiple_value_columns = dataset.columns[dataset.nunique()>2].tolist()\n",
    "# Remove 'Label' from values as data is going to be splited lately\n",
    "multiple_value_columns.remove('Label')\n",
    "print(\"Empty columns \", empty_columns)\n",
    "print(\"Only one different value columns \", one_value_columns)\n",
    "print(\"Int value params\", multiple_value_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a first look to parameters list we could infer: \n",
    "- Most of parameters, apart from label and the ones described below, contain bool values.\n",
    "- Parameters ['Q350', 'Q353', 'Q356', 'Q359', 'Q362', 'Q365', 'Q368', 'Q371'] contain only one different value so probably they are good candidates for being removed from dataset.\n",
    "- Parameters ['Q74', 'Q76', 'Q78', 'Q80', 'Q82', 'Q84', 'Q86', 'Q88', 'Q90', 'Q92', 'Q94', 'Q96', 'Q100', 'Q101', 'Q102'] have no values at all, so we can delete them.\n",
    "- Parameter ['Q10', 'Q19', 'Q49', 'Q50', 'Q51', 'Q103', 'Q104', 'Q105', 'Q106', 'Q107', 'Q108', 'Q114', 'Q115', 'Q116', 'Q160', 'Q161', 'Q162'] contain int type values and are susceptible for regularizarion\n",
    "\n",
    "There is no need for one hot encoding as there are not string valued parameters. We'll perform it later with 'Label' column in the prediction model section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see graphically which is the disease distribution inside dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a49933650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['Label'].value_counts()[:20].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we are going to remove empty and one single value colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features  400\n"
     ]
    }
   ],
   "source": [
    "original_number_of_features = len(dataset.columns)-1 #Label\n",
    "print(\"Original number of features \",original_number_of_features)\n",
    "dataset = dataset.drop(empty_columns, axis=1)\n",
    "dataset = dataset.drop(one_value_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Cefaleas/TMD\n",
      "1      DM. Referido\n",
      "2           DDSRSLA\n",
      "3           DDCRCBI\n",
      "4           DDSRCLA\n",
      "           ...     \n",
      "676    DM. Referido\n",
      "677    DM. Referido\n",
      "678         Mialgia\n",
      "679         DDSRSLA\n",
      "680         Mialgia\n",
      "Name: Label, Length: 681, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Label'])\n",
    "# Split the data into features and target label\n",
    "diagnosis_raw = dataset['Label']\n",
    "features_raw = dataset.drop('Label', axis = 1)\n",
    "# Get number of deseases. We are going to use it for, for instance, set the output layer size in the prediction section\n",
    "number_of_diseases = len(diagnosis_raw.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let going to log transform to numerical values to ensure all values are in range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9       Q10  ...  Q391  Q392  Q393  Q394  \\\n",
       "0   1   1   0   1   0   1   1   0   1  0.292481  ...     1     0     0     1   \n",
       "1   1   0   1   1   1   1   1   1   1  0.903677  ...     0     1     0     1   \n",
       "2   0   0   0   0   0   0   0   1   0  0.500000  ...     1     1     1     1   \n",
       "3   0   0   0   1   0   0   0   0   1  0.660964  ...     1     1     0     1   \n",
       "4   1   0   0   0   1   1   0   0   0  0.792481  ...     0     1     0     0   \n",
       "\n",
       "   Q395  Q396  Q397  Q398  Q399  Q400  \n",
       "0     0     1     0     1     0     0  \n",
       "1     0     1     0     1     0     0  \n",
       "2     1     0     1     0     0     0  \n",
       "3     0     1     1     1     0     0  \n",
       "4     1     1     1     0     0     1  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log transform numerical value colums\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[multiple_value_columns] = features_raw[multiple_value_columns].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[multiple_value_columns] = scaler.fit_transform(features_log_transformed[multiple_value_columns])\n",
    "\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points considered outliers for the feature 'Q114':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9       Q10  ...  Q391  Q392  Q393  \\\n",
       "72    1   0   1   1   1   1   1   1   1  0.000000  ...     1     1     1   \n",
       "210   1   0   1   1   1   1   1   1   1  0.292481  ...     1     1     0   \n",
       "251   1   0   0   1   1   1   1   1   1  0.500000  ...     0     1     0   \n",
       "356   1   0   1   1   1   1   1   1   1  0.500000  ...     0     1     1   \n",
       "401   1   1   1   0   1   1   1   1   1  0.292481  ...     1     1     0   \n",
       "449   1   1   1   1   1   1   1   1   1  0.500000  ...     1     1     0   \n",
       "\n",
       "     Q394  Q395  Q396  Q397  Q398  Q399  Q400  \n",
       "72      1     0     0     0     0     0     1  \n",
       "210     1     0     0     0     0     1     0  \n",
       "251     1     1     1     0     1     0     0  \n",
       "356     0     1     1     0     0     0     1  \n",
       "401     1     0     1     1     1     0     0  \n",
       "449     0     0     1     1     1     0     0  \n",
       "\n",
       "[6 rows x 377 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points considered outliers for the feature 'Q116':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9       Q10  ...  Q391  Q392  Q393  \\\n",
       "2     0   0   0   0   0   0   0   1   0  0.500000  ...     1     1     1   \n",
       "14    1   1   0   0   1   1   1   1   1  0.660964  ...     0     0     0   \n",
       "16    0   0   0   0   0   0   0   0   0  0.792481  ...     1     1     1   \n",
       "29    0   0   0   0   0   0   0   0   0  0.000000  ...     0     1     0   \n",
       "31    1   0   1   0   0   1   0   0   1  1.000000  ...     1     1     1   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..       ...  ...   ...   ...   ...   \n",
       "628   0   1   0   0   0   0   0   0   1  1.000000  ...     1     0     0   \n",
       "629   1   0   1   1   1   1   1   0   0  0.903677  ...     1     1     0   \n",
       "641   0   1   1   0   0   1   1   0   1  0.792481  ...     0     0     1   \n",
       "642   1   1   0   0   1   1   1   1   1  1.000000  ...     0     0     0   \n",
       "679   0   0   0   1   1   0   0   1   1  0.000000  ...     1     1     1   \n",
       "\n",
       "     Q394  Q395  Q396  Q397  Q398  Q399  Q400  \n",
       "2       1     1     0     1     0     0     0  \n",
       "14      1     0     0     1     1     0     0  \n",
       "16      1     0     1     1     1     0     0  \n",
       "29      1     0     1     1     0     0     1  \n",
       "31      1     1     0     0     0     0     1  \n",
       "..    ...   ...   ...   ...   ...   ...   ...  \n",
       "628     0     0     0     1     0     0     1  \n",
       "629     0     1     0     1     0     1     0  \n",
       "641     1     1     1     0     0     1     0  \n",
       "642     0     0     0     1     1     0     0  \n",
       "679     1     1     1     0     1     0     0  \n",
       "\n",
       "[73 rows x 377 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points considered outliers for the feature 'Q160':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9       Q10  ...  Q391  Q392  Q393  \\\n",
       "3     0   0   0   1   0   0   0   0   1  0.660964  ...     1     1     0   \n",
       "10    0   0   0   0   0   0   0   0   1  0.792481  ...     1     1     1   \n",
       "15    1   0   1   0   1   1   1   1   1  0.500000  ...     0     1     0   \n",
       "21    0   0   0   1   0   0   0   0   1  0.500000  ...     1     0     1   \n",
       "29    0   0   0   0   0   0   0   0   0  0.000000  ...     0     1     0   \n",
       "38    0   0   0   0   0   0   0   1   0  0.292481  ...     1     1     0   \n",
       "54    1   0   0   1   1   1   1   1   1  0.660964  ...     0     0     0   \n",
       "65    1   0   0   1   1   1   1   1   1  0.792481  ...     1     1     1   \n",
       "83    0   0   0   1   0   0   0   0   0  0.903677  ...     1     1     0   \n",
       "84    1   1   1   0   1   1   1   1   1  0.000000  ...     0     0     0   \n",
       "87    1   1   0   0   1   1   1   1   1  0.792481  ...     1     0     0   \n",
       "102   0   0   0   0   0   0   0   0   0  0.500000  ...     1     0     0   \n",
       "140   1   1   0   1   1   1   1   0   1  0.660964  ...     0     0     0   \n",
       "151   1   0   0   1   1   1   1   1   1  0.292481  ...     0     0     0   \n",
       "160   0   0   0   1   0   0   0   0   0  0.792481  ...     1     1     1   \n",
       "162   1   1   0   1   0   1   1   0   1  0.000000  ...     0     1     0   \n",
       "170   1   0   1   1   1   1   1   1   1  0.000000  ...     0     1     0   \n",
       "182   1   1   1   0   1   1   1   1   1  0.792481  ...     1     1     0   \n",
       "206   0   0   1   0   0   0   0   0   0  0.500000  ...     1     1     0   \n",
       "211   0   0   0   0   0   0   0   0   1  0.792481  ...     1     0     1   \n",
       "213   1   0   0   1   1   1   1   1   1  0.903677  ...     1     1     0   \n",
       "220   0   0   1   0   0   0   0   0   0  0.000000  ...     1     0     1   \n",
       "226   1   1   0   1   1   1   1   1   1  0.792481  ...     1     1     1   \n",
       "241   1   0   1   1   1   1   1   1   1  0.660964  ...     0     1     1   \n",
       "255   1   0   0   1   1   1   1   1   1  0.500000  ...     1     0     0   \n",
       "263   1   1   1   0   1   1   1   1   1  0.500000  ...     0     0     0   \n",
       "268   0   0   0   0   0   0   0   0   0  0.660964  ...     1     0     1   \n",
       "278   1   0   0   0   1   1   1   1   1  0.903677  ...     0     1     0   \n",
       "291   1   1   1   1   1   0   1   0   1  0.500000  ...     0     1     1   \n",
       "319   1   0   1   1   1   1   1   1   1  0.903677  ...     1     1     0   \n",
       "334   1   0   0   0   0   0   0   0   0  0.000000  ...     1     1     0   \n",
       "341   1   0   0   1   1   1   1   1   1  0.660964  ...     1     1     1   \n",
       "355   1   0   1   1   1   1   1   1   1  0.500000  ...     1     0     0   \n",
       "360   1   0   1   1   1   1   1   1   1  0.500000  ...     1     0     1   \n",
       "401   1   1   1   0   1   1   1   1   1  0.292481  ...     1     1     0   \n",
       "409   1   0   1   1   1   1   1   1   1  0.500000  ...     1     0     1   \n",
       "412   0   0   0   1   0   0   0   0   1  1.000000  ...     1     1     0   \n",
       "430   1   0   0   0   1   1   1   0   0  1.000000  ...     1     1     1   \n",
       "431   1   0   1   1   1   1   1   1   1  0.292481  ...     1     0     0   \n",
       "438   1   0   0   1   0   1   1   0   1  0.292481  ...     1     1     1   \n",
       "485   1   1   1   0   1   1   1   1   1  0.000000  ...     0     1     0   \n",
       "519   1   0   0   1   1   1   1   1   1  0.292481  ...     1     0     1   \n",
       "524   0   0   0   1   0   0   0   0   0  1.000000  ...     0     0     0   \n",
       "530   1   0   0   1   1   1   1   1   1  0.292481  ...     0     1     0   \n",
       "548   0   0   0   1   0   0   0   0   0  0.660964  ...     1     0     1   \n",
       "549   1   0   1   1   1   1   1   0   1  0.500000  ...     1     0     0   \n",
       "561   1   1   1   1   1   1   1   1   1  0.792481  ...     0     1     0   \n",
       "587   0   0   0   1   0   0   0   0   0  0.500000  ...     0     0     1   \n",
       "591   0   0   0   0   0   0   0   1   1  0.292481  ...     1     0     0   \n",
       "599   1   0   1   1   1   1   1   1   1  0.660964  ...     1     1     1   \n",
       "603   0   0   0   1   0   0   0   0   1  0.903677  ...     1     1     1   \n",
       "610   1   0   1   1   1   1   1   1   1  0.500000  ...     0     1     1   \n",
       "613   1   0   1   1   1   1   1   1   1  0.660964  ...     1     0     1   \n",
       "625   0   0   0   0   0   0   0   0   1  0.292481  ...     1     1     0   \n",
       "663   1   1   1   1   1   1   1   1   1  0.903677  ...     0     1     1   \n",
       "665   0   0   0   0   0   0   0   0   1  0.792481  ...     1     0     1   \n",
       "680   1   1   0   1   1   1   1   1   1  0.292481  ...     1     1     1   \n",
       "\n",
       "     Q394  Q395  Q396  Q397  Q398  Q399  Q400  \n",
       "3       1     0     1     1     1     0     0  \n",
       "10      1     1     0     0     1     0     0  \n",
       "15      1     1     1     1     0     1     0  \n",
       "21      0     1     1     1     1     0     0  \n",
       "29      1     0     1     1     0     0     1  \n",
       "38      0     1     1     1     0     1     0  \n",
       "54      1     0     1     1     0     0     0  \n",
       "65      0     0     1     0     0     0     1  \n",
       "83      1     0     0     1     0     1     0  \n",
       "84      0     0     0     0     0     0     1  \n",
       "87      1     1     1     1     1     0     0  \n",
       "102     0     1     1     1     1     0     0  \n",
       "140     0     0     1     1     0     1     0  \n",
       "151     1     0     1     0     0     1     0  \n",
       "160     1     0     1     0     0     0     1  \n",
       "162     0     0     1     0     0     1     0  \n",
       "170     0     1     1     0     0     0     1  \n",
       "182     1     1     1     0     1     0     0  \n",
       "206     0     0     0     0     0     0     1  \n",
       "211     1     0     1     0     1     0     0  \n",
       "213     0     1     1     1     0     1     0  \n",
       "220     1     1     0     1     0     0     1  \n",
       "226     1     1     1     0     0     1     0  \n",
       "241     0     1     0     0     0     1     0  \n",
       "255     1     0     1     1     1     1     0  \n",
       "263     0     0     0     0     1     0     0  \n",
       "268     1     0     0     0     1     0     0  \n",
       "278     1     0     0     1     1     0     0  \n",
       "291     0     1     0     1     0     0     1  \n",
       "319     0     0     1     1     0     0     1  \n",
       "334     1     1     0     1     0     0     1  \n",
       "341     0     0     1     0     0     1     0  \n",
       "355     0     0     1     1     1     0     0  \n",
       "360     1     1     0     1     1     0     0  \n",
       "401     1     0     1     1     1     0     0  \n",
       "409     1     0     0     1     0     0     1  \n",
       "412     1     1     1     1     1     0     0  \n",
       "430     0     1     0     0     0     0     1  \n",
       "431     0     0     0     1     0     1     0  \n",
       "438     0     0     1     1     1     0     0  \n",
       "485     0     1     1     1     1     0     0  \n",
       "519     0     0     1     0     1     0     0  \n",
       "524     1     0     1     1     0     0     1  \n",
       "530     1     0     1     1     0     1     0  \n",
       "548     1     1     0     1     1     0     0  \n",
       "549     0     1     1     1     1     0     0  \n",
       "561     0     1     1     0     0     0     1  \n",
       "587     1     1     1     1     1     0     0  \n",
       "591     1     1     1     1     0     0     1  \n",
       "599     1     1     0     1     0     0     1  \n",
       "603     0     1     1     1     1     0     0  \n",
       "610     0     0     1     0     0     0     1  \n",
       "613     0     1     1     0     1     0     0  \n",
       "625     1     1     0     0     0     0     1  \n",
       "663     0     0     1     1     1     0     0  \n",
       "665     1     1     1     1     1     0     0  \n",
       "680     0     1     0     1     1     0     0  \n",
       "\n",
       "[57 rows x 377 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected in more than one feature: 6\n",
      "Original records: 681\n",
      "Records once outliers have been removed: 675\n"
     ]
    }
   ],
   "source": [
    "# For each integer feature find the data points with extreme high or low values\n",
    "# List to store outliers detected in loop\n",
    "dataset = features_log_minmax_transform\n",
    "all_outliers = []\n",
    "for feature in multiple_value_columns :\n",
    "    \n",
    "    Q1 = np.percentile(dataset[feature], 25)\n",
    "    Q3 = np.percentile(dataset[feature], 75)\n",
    "    step = (Q3 - Q1)*1.5\n",
    "    \n",
    "    feature_outliers = dataset[~((dataset[feature] >= Q1 - step) & (dataset[feature] <= Q3 + step))]\n",
    "    if len(feature_outliers) == 0 :\n",
    "        continue\n",
    "    print(\"Data points considered outliers for the feature '{}':\".format(feature))\n",
    "    display(feature_outliers)\n",
    "    \n",
    "    all_outliers.extend(feature_outliers.index.values)\n",
    "    \n",
    "import collections\n",
    "outliers =  [item for item, count in collections.Counter(all_outliers).items() if count > 1]\n",
    "# Remove the outliers present in more than one feature, if any were specified\n",
    "good_data = dataset.drop(dataset.index[outliers]).reset_index(drop = True)\n",
    "print('Outliers detected in more than one feature:',len(outliers))\n",
    "print('Original records:',len(dataset))\n",
    "print('Records once outliers have been removed:',len(good_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to delete outliers in diagnosis_raw in order to keep same amount of records in features and label dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original records: 681\n",
      "Records once outliers have been removed: 675\n"
     ]
    }
   ],
   "source": [
    "diagnosis = diagnosis_raw.drop(dataset.index[outliers]).reset_index(drop = True)\n",
    "print('Original records:',len(diagnosis_raw))\n",
    "print('Records once outliers have been removed:',len(diagnosis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "At this point, we have available the following variables, that will be used extensively in the next sections:\n",
    "\n",
    "- good_data: Regularized features dataset (without outliers)\n",
    "- diagnosis: Dataset containing Labels corresponding to features dataset,\n",
    "- number_of_diseases: Number of different diseases to diagnose\n",
    "\n",
    "We are going to store these datasets in files on order to use them throughout next sections without needing to execute all previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data.to_pickle('data/good_data.pkl')\n",
    "diagnosis.to_pickle('data/diagnosis.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of the project is to provide doctors a prediction function that helps them to diagnose a TMD disorder based on patient answers to questionaries. Along previous steps, we have declared a set of variables that are going to be useful for the prediction model.\n",
    "\n",
    "- **dataset**: Imported from `data/good_data.pkl` file. Regularized features dataset (without outliers) \n",
    "- **diagnosis**: Imported from `data/diagnosis_raw.pkl` file. Dataset containing Labels corresponding to features dataset.\n",
    "- **number_of_diseases**: Number of different diseases to diagnose\n",
    "- **reduced_dataset**: Imported from `data/good_data_reduced.pkl` file. Regularized features dataset without columns deleted in previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n",
      "675\n",
      "377\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('data/good_data.pkl')\n",
    "diagnosis = pd.read_pickle('data/diagnosis.pkl')\n",
    "print(len(dataset))\n",
    "print(len(diagnosis))\n",
    "print(len(dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Cefaleas/TMD\n",
       "1      DM. Referido\n",
       "2           DDSRSLA\n",
       "3           DDCRCBI\n",
       "4           DDSRCLA\n",
       "5              DDCR\n",
       "6           Mialgia\n",
       "7     Mialgia Local\n",
       "8              DDCR\n",
       "9         Artralgia\n",
       "10          DDCRCBI\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label dataset one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply one hot encoding to diagnosis labels (as we are dealing with 11 different labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(diagnosis)\n",
    "encoded_Y = encoder.transform(diagnosis)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dummy_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                24192     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                363       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 26,635\n",
      "Trainable params: 26,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "# First Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal', input_dim=len(dataset.columns)))\n",
    "classifier.add(Dropout(0.2))\n",
    "# Second  Hidden Layer\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'),)\n",
    "classifier.add(Dropout(0.2))\n",
    "# Output Layer\n",
    "classifier.add(Dense(number_of_diseases, activation='softmax', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 405 samples, validate on 135 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/ucp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.5432 - acc: 0.9091 - val_loss: 0.2713 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90909, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 0s 500us/step - loss: 0.4805 - acc: 0.9145 - val_loss: 0.1990 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90909 to 0.91852, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 0s 504us/step - loss: 0.4375 - acc: 0.9311 - val_loss: 0.1342 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91852 to 0.95892, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 0s 513us/step - loss: 0.4184 - acc: 0.9542 - val_loss: 0.0818 - val_acc: 0.9704\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95892 to 0.97037, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 0s 507us/step - loss: 0.3258 - acc: 0.9639 - val_loss: 0.0584 - val_acc: 0.9771\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97037 to 0.97710, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 0s 509us/step - loss: 0.2843 - acc: 0.9699 - val_loss: 0.0517 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97710 to 0.98855, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 0s 505us/step - loss: 0.3531 - acc: 0.9652 - val_loss: 0.0434 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98855\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 0s 509us/step - loss: 0.3273 - acc: 0.9728 - val_loss: 0.0326 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98855\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 0s 514us/step - loss: 0.3247 - acc: 0.9740 - val_loss: 0.0265 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98855 to 0.99057, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 0s 529us/step - loss: 0.3348 - acc: 0.9753 - val_loss: 0.0229 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99057\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 0s 515us/step - loss: 0.3616 - acc: 0.9684 - val_loss: 0.0261 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99057 to 0.99327, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 0s 527us/step - loss: 0.3033 - acc: 0.9769 - val_loss: 0.0202 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.99327 to 0.99798, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 0s 554us/step - loss: 0.3210 - acc: 0.9789 - val_loss: 0.0179 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99798\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 0s 520us/step - loss: 0.2985 - acc: 0.9796 - val_loss: 0.0171 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99798\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 0s 517us/step - loss: 0.3280 - acc: 0.9780 - val_loss: 0.0131 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99798\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 0s 504us/step - loss: 0.2409 - acc: 0.9832 - val_loss: 0.0113 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.99798 to 0.99865, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 0s 526us/step - loss: 0.3523 - acc: 0.9755 - val_loss: 0.0110 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99865\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 0s 507us/step - loss: 0.2736 - acc: 0.9814 - val_loss: 0.0132 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99865\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 0s 509us/step - loss: 0.2922 - acc: 0.9791 - val_loss: 0.0114 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99865\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 0s 499us/step - loss: 0.3285 - acc: 0.9785 - val_loss: 0.0083 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99865\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 0s 498us/step - loss: 0.3000 - acc: 0.9796 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99865\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 0s 506us/step - loss: 0.2986 - acc: 0.9809 - val_loss: 0.0063 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99865\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 0s 499us/step - loss: 0.3246 - acc: 0.9785 - val_loss: 0.0064 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99865\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 0s 504us/step - loss: 0.3151 - acc: 0.9800 - val_loss: 0.0068 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99865\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 0s 511us/step - loss: 0.2818 - acc: 0.9825 - val_loss: 0.0077 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99865\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 0s 521us/step - loss: 0.2966 - acc: 0.9807 - val_loss: 0.0060 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.99865\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 0s 527us/step - loss: 0.3237 - acc: 0.9782 - val_loss: 0.0065 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.99865\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 0s 531us/step - loss: 0.3070 - acc: 0.9805 - val_loss: 0.0102 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99865\n",
      "Epoch 29/100\n",
      "405/405 [==============================] - 0s 530us/step - loss: 0.2959 - acc: 0.9814 - val_loss: 0.0053 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99865\n",
      "Epoch 30/100\n",
      "405/405 [==============================] - 0s 551us/step - loss: 0.2313 - acc: 0.9854 - val_loss: 0.0051 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99865\n",
      "Epoch 31/100\n",
      "405/405 [==============================] - 0s 571us/step - loss: 0.3443 - acc: 0.9780 - val_loss: 0.0049 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99865\n",
      "Epoch 32/100\n",
      "405/405 [==============================] - 0s 579us/step - loss: 0.3349 - acc: 0.9793 - val_loss: 0.0060 - val_acc: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99865\n",
      "Epoch 33/100\n",
      "405/405 [==============================] - 0s 595us/step - loss: 0.2947 - acc: 0.9818 - val_loss: 0.0043 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99865\n",
      "Epoch 34/100\n",
      "405/405 [==============================] - 0s 582us/step - loss: 0.3308 - acc: 0.9796 - val_loss: 0.0042 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99865\n",
      "Epoch 35/100\n",
      "405/405 [==============================] - 0s 584us/step - loss: 0.3204 - acc: 0.9802 - val_loss: 0.0042 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99865\n",
      "Epoch 36/100\n",
      "405/405 [==============================] - 0s 590us/step - loss: 0.2859 - acc: 0.9816 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.99865 to 1.00000, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 37/100\n",
      "405/405 [==============================] - 0s 638us/step - loss: 0.2818 - acc: 0.9818 - val_loss: 0.0072 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 1.00000\n",
      "Epoch 38/100\n",
      "405/405 [==============================] - 0s 630us/step - loss: 0.2872 - acc: 0.9823 - val_loss: 0.0041 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 1.00000\n",
      "Epoch 39/100\n",
      "405/405 [==============================] - 0s 603us/step - loss: 0.2658 - acc: 0.9834 - val_loss: 0.0031 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 1.00000\n",
      "Epoch 40/100\n",
      "405/405 [==============================] - 0s 584us/step - loss: 0.2774 - acc: 0.9820 - val_loss: 0.0055 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 1.00000\n",
      "Epoch 41/100\n",
      "405/405 [==============================] - 0s 600us/step - loss: 0.3161 - acc: 0.9805 - val_loss: 0.0036 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 1.00000\n",
      "Epoch 42/100\n",
      "405/405 [==============================] - 0s 586us/step - loss: 0.2444 - acc: 0.9843 - val_loss: 0.0045 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 1.00000\n",
      "Epoch 43/100\n",
      "405/405 [==============================] - 0s 577us/step - loss: 0.2978 - acc: 0.9816 - val_loss: 0.0052 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 1.00000\n",
      "Epoch 44/100\n",
      "405/405 [==============================] - 0s 586us/step - loss: 0.2407 - acc: 0.9850 - val_loss: 0.0041 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 1.00000\n",
      "Epoch 45/100\n",
      "405/405 [==============================] - 0s 578us/step - loss: 0.2794 - acc: 0.9827 - val_loss: 0.0054 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 1.00000\n",
      "Epoch 46/100\n",
      "405/405 [==============================] - 0s 567us/step - loss: 0.2762 - acc: 0.9827 - val_loss: 0.0059 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 1.00000\n",
      "Epoch 47/100\n",
      "405/405 [==============================] - 0s 552us/step - loss: 0.3229 - acc: 0.9800 - val_loss: 0.0061 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 1.00000\n",
      "Epoch 48/100\n",
      "405/405 [==============================] - 0s 560us/step - loss: 0.3413 - acc: 0.9785 - val_loss: 0.0077 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 1.00000\n",
      "Epoch 49/100\n",
      "405/405 [==============================] - 0s 554us/step - loss: 0.2836 - acc: 0.9825 - val_loss: 0.0065 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 1.00000\n",
      "Epoch 50/100\n",
      "405/405 [==============================] - 0s 556us/step - loss: 0.2836 - acc: 0.9823 - val_loss: 0.0035 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 1.00000\n",
      "Epoch 51/100\n",
      "405/405 [==============================] - 0s 556us/step - loss: 0.2763 - acc: 0.9825 - val_loss: 0.0042 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 1.00000\n",
      "Epoch 52/100\n",
      "405/405 [==============================] - 0s 555us/step - loss: 0.2759 - acc: 0.9829 - val_loss: 0.0043 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 1.00000\n",
      "Epoch 53/100\n",
      "405/405 [==============================] - 0s 556us/step - loss: 0.2951 - acc: 0.9809 - val_loss: 0.0073 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 1.00000\n",
      "Epoch 54/100\n",
      "405/405 [==============================] - 0s 556us/step - loss: 0.2904 - acc: 0.9820 - val_loss: 0.0028 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 1.00000\n",
      "Epoch 55/100\n",
      "405/405 [==============================] - 0s 555us/step - loss: 0.3375 - acc: 0.9789 - val_loss: 0.0064 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 1.00000\n",
      "Epoch 56/100\n",
      "405/405 [==============================] - 0s 556us/step - loss: 0.2869 - acc: 0.9823 - val_loss: 0.0059 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 1.00000\n",
      "Epoch 57/100\n",
      "405/405 [==============================] - 0s 555us/step - loss: 0.2975 - acc: 0.9816 - val_loss: 0.0061 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 1.00000\n",
      "Epoch 58/100\n",
      "405/405 [==============================] - 0s 554us/step - loss: 0.3201 - acc: 0.9796 - val_loss: 0.0052 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 1.00000\n",
      "Epoch 59/100\n",
      "405/405 [==============================] - 0s 554us/step - loss: 0.3161 - acc: 0.9800 - val_loss: 0.0031 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 1.00000\n",
      "Epoch 60/100\n",
      "405/405 [==============================] - 0s 551us/step - loss: 0.3045 - acc: 0.9811 - val_loss: 0.0035 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 1.00000\n",
      "Epoch 61/100\n",
      "405/405 [==============================] - 0s 557us/step - loss: 0.2541 - acc: 0.9843 - val_loss: 0.0048 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 1.00000\n",
      "Epoch 62/100\n",
      "405/405 [==============================] - 0s 559us/step - loss: 0.2186 - acc: 0.9859 - val_loss: 0.0035 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 1.00000\n",
      "Epoch 63/100\n",
      "405/405 [==============================] - 0s 560us/step - loss: 0.3197 - acc: 0.9798 - val_loss: 0.0062 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 1.00000\n",
      "Epoch 64/100\n",
      "405/405 [==============================] - 0s 553us/step - loss: 0.3093 - acc: 0.9802 - val_loss: 0.0039 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 1.00000\n",
      "Epoch 65/100\n",
      "405/405 [==============================] - 0s 550us/step - loss: 0.3300 - acc: 0.9796 - val_loss: 0.0055 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 1.00000\n",
      "Epoch 66/100\n",
      "405/405 [==============================] - 0s 560us/step - loss: 0.2872 - acc: 0.9816 - val_loss: 0.0041 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 1.00000\n",
      "Epoch 67/100\n",
      "405/405 [==============================] - 0s 558us/step - loss: 0.2837 - acc: 0.9818 - val_loss: 0.0049 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 1.00000\n",
      "Epoch 68/100\n",
      "405/405 [==============================] - 0s 560us/step - loss: 0.2939 - acc: 0.9816 - val_loss: 0.0043 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 1.00000\n",
      "Epoch 69/100\n",
      "405/405 [==============================] - 0s 560us/step - loss: 0.2575 - acc: 0.9841 - val_loss: 0.0044 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 1.00000\n",
      "Epoch 70/100\n",
      "405/405 [==============================] - 0s 578us/step - loss: 0.3044 - acc: 0.9811 - val_loss: 0.0057 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 1.00000\n",
      "Epoch 71/100\n",
      "405/405 [==============================] - 0s 556us/step - loss: 0.3483 - acc: 0.9782 - val_loss: 0.0027 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 1.00000\n",
      "Epoch 72/100\n",
      "405/405 [==============================] - 0s 571us/step - loss: 0.2831 - acc: 0.9823 - val_loss: 0.0033 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 1.00000\n",
      "Epoch 73/100\n",
      "405/405 [==============================] - 0s 603us/step - loss: 0.3043 - acc: 0.9811 - val_loss: 0.0042 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 1.00000\n",
      "Epoch 74/100\n",
      "405/405 [==============================] - 0s 560us/step - loss: 0.2938 - acc: 0.9818 - val_loss: 0.0044 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 1.00000\n",
      "Epoch 75/100\n",
      "405/405 [==============================] - 0s 554us/step - loss: 0.2790 - acc: 0.9827 - val_loss: 0.0044 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 1.00000\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 0s 562us/step - loss: 0.2834 - acc: 0.9823 - val_loss: 0.0030 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 1.00000\n",
      "Epoch 77/100\n",
      "405/405 [==============================] - 0s 555us/step - loss: 0.3084 - acc: 0.9809 - val_loss: 0.0075 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 1.00000\n",
      "Epoch 78/100\n",
      "405/405 [==============================] - 0s 547us/step - loss: 0.3082 - acc: 0.9809 - val_loss: 0.0035 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 1.00000\n",
      "Epoch 79/100\n",
      "405/405 [==============================] - 0s 554us/step - loss: 0.3592 - acc: 0.9776 - val_loss: 0.0041 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 1.00000\n",
      "Epoch 80/100\n",
      "405/405 [==============================] - 0s 548us/step - loss: 0.3009 - acc: 0.9814 - val_loss: 0.0055 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 1.00000\n",
      "Epoch 81/100\n",
      "405/405 [==============================] - 0s 567us/step - loss: 0.2938 - acc: 0.9816 - val_loss: 0.0033 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 1.00000\n",
      "Epoch 82/100\n",
      "405/405 [==============================] - 0s 568us/step - loss: 0.3552 - acc: 0.9780 - val_loss: 0.0066 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 1.00000\n",
      "Epoch 83/100\n",
      "405/405 [==============================] - 0s 565us/step - loss: 0.2223 - acc: 0.9856 - val_loss: 0.0059 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 1.00000\n",
      "Epoch 84/100\n",
      "405/405 [==============================] - 0s 567us/step - loss: 0.2985 - acc: 0.9796 - val_loss: 0.0098 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 1.00000\n",
      "Epoch 85/100\n",
      "405/405 [==============================] - 0s 598us/step - loss: 0.3046 - acc: 0.9811 - val_loss: 0.0050 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 1.00000\n",
      "Epoch 86/100\n",
      "405/405 [==============================] - 0s 576us/step - loss: 0.3051 - acc: 0.9809 - val_loss: 0.0046 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 1.00000\n",
      "Epoch 87/100\n",
      "405/405 [==============================] - 0s 597us/step - loss: 0.3200 - acc: 0.9796 - val_loss: 0.0098 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 1.00000\n",
      "Epoch 88/100\n",
      "405/405 [==============================] - 0s 587us/step - loss: 0.2538 - acc: 0.9843 - val_loss: 0.0072 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 1.00000\n",
      "Epoch 89/100\n",
      "405/405 [==============================] - 0s 604us/step - loss: 0.3015 - acc: 0.9809 - val_loss: 0.0104 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 1.00000\n",
      "Epoch 90/100\n",
      "405/405 [==============================] - 0s 610us/step - loss: 0.3442 - acc: 0.9787 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 1.00000\n",
      "Epoch 91/100\n",
      "405/405 [==============================] - 0s 584us/step - loss: 0.2797 - acc: 0.9823 - val_loss: 0.0056 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 1.00000\n",
      "Epoch 92/100\n",
      "405/405 [==============================] - 0s 610us/step - loss: 0.2683 - acc: 0.9834 - val_loss: 0.0079 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 1.00000\n",
      "Epoch 93/100\n",
      "405/405 [==============================] - 0s 598us/step - loss: 0.2683 - acc: 0.9834 - val_loss: 0.0074 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 1.00000\n",
      "Epoch 94/100\n",
      "405/405 [==============================] - 0s 590us/step - loss: 0.2973 - acc: 0.9814 - val_loss: 0.0053 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 1.00000\n",
      "Epoch 95/100\n",
      "405/405 [==============================] - 0s 588us/step - loss: 0.2574 - acc: 0.9841 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 1.00000\n",
      "Epoch 96/100\n",
      "405/405 [==============================] - 0s 598us/step - loss: 0.2864 - acc: 0.9820 - val_loss: 0.0084 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 1.00000\n",
      "Epoch 97/100\n",
      "405/405 [==============================] - 0s 577us/step - loss: 0.3910 - acc: 0.9755 - val_loss: 0.0076 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 1.00000\n",
      "Epoch 98/100\n",
      "405/405 [==============================] - 0s 603us/step - loss: 0.2546 - acc: 0.9838 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 1.00000\n",
      "Epoch 99/100\n",
      "405/405 [==============================] - 0s 586us/step - loss: 0.3477 - acc: 0.9785 - val_loss: 0.0056 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 1.00000\n",
      "Epoch 100/100\n",
      "405/405 [==============================] - 0s 583us/step - loss: 0.2935 - acc: 0.9818 - val_loss: 0.0088 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 1.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4a0b3790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "filepath=\"saved_models/weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "classifier.fit(X_train, y_train, validation_split=0.25, epochs=epochs, batch_size=10, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval model: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 [==============================] - 0s 52us/step\n",
      "Accuracy using training set: 0.9996632995428862\n"
     ]
    }
   ],
   "source": [
    "# Accuracy over training set\n",
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "print(\"Accuracy using training set:\",eval_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using testing set: 0.9851851851851852\n"
     ]
    }
   ],
   "source": [
    "# Accuracy over testing set\n",
    "classifier.load_weights('saved_models/weights.best.hdf5')\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(\"Accuracy using testing set:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved an accuracy using test dataset of about **95%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have had to include several changes in the original NN architecture due to high overfitting Original architecture achieved only an about 77% accuracy using testing set, although training data accuracy was quite similar to previuos one. Some of the changes were:\n",
    "\n",
    "- Use L1 and L2 regularizations: Did not work. In fact, we got worse results.\n",
    "- Increase output size of layers. It improved accuracy (testing set) by more than 10 points\n",
    "- Change output layer activarion function from `sigmoid` to `softmax`. It worked really well.\n",
    "\n",
    "After doing that, accuracy for the preduction model using the reduced set of data is even a little bit better than using the full dataset. \n",
    "\n",
    "Probably ther are still ways for improving this values and I think that it is going to significantlly increase as we get more data. Probably, number of records in original dataset are not enought to properly train our prediction model. Anyway, one of the project conclussions is that, probably (we don't still know if meaybe new diseases are going to be included), we can make diagnosis predictions using 81 less questions (400 of the original dataset vs. 319 of the reduced one). This should be evaluated by experts in the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1a5f1129d0>,\n",
       "  <matplotlib.axis.YTick at 0x1a5f1120d0>,\n",
       "  <matplotlib.axis.YTick at 0x1a5c139b90>,\n",
       "  <matplotlib.axis.YTick at 0x1a5de97d10>,\n",
       "  <matplotlib.axis.YTick at 0x1a5de9f2d0>,\n",
       "  <matplotlib.axis.YTick at 0x1a5de97850>,\n",
       "  <matplotlib.axis.YTick at 0x1a5de91d10>,\n",
       "  <matplotlib.axis.YTick at 0x1a5de9f690>,\n",
       "  <matplotlib.axis.YTick at 0x1a5de9fb90>],\n",
       " <a list of 9 Text yticklabel objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We have to change one hot encoded values for real prediction values\n",
    "#diagnosis_raw[np.argmax(predicted_value)]\n",
    "#confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "pred = []\n",
    "for i in y_pred :\n",
    "    pred.append(diagnosis_raw[np.argmax(i)])\n",
    "    \n",
    "test = []\n",
    "for i in y_test:\n",
    "    test.append(diagnosis_raw[np.argmax(i)])\n",
    "\n",
    "cm = confusion_matrix(test, pred)\n",
    "\n",
    "norm_conf = []\n",
    "for i in cm:\n",
    "    a = 0\n",
    "    tmp_arr = []\n",
    "    a = sum(i, 0)\n",
    "    for j in i:\n",
    "        tmp_arr.append(float(j)/float(a))\n",
    "    norm_conf.append(tmp_arr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "ax.grid(False)\n",
    "res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                interpolation='nearest')\n",
    "\n",
    "width, height = cm.shape\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        ax.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', color='white')\n",
    "\n",
    "cb = fig.colorbar(res)\n",
    "plt.xticks(range(width), np.unique(diagnosis_raw)[:width], rotation=90)\n",
    "plt.yticks(range(height), np.unique(diagnosis_raw)[:height])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_1 = Sequential()\n",
    "# First Hidden Layer\n",
    "classifier_1.add(Dense(64, activation='relu', kernel_initializer='random_normal', input_dim=len(dataset.columns)))\n",
    "classifier_1.add(Dropout(0.2))\n",
    "# Second  Hidden Layer\n",
    "classifier_1.add(Dense(32, activation='relu', kernel_initializer='random_normal'),)\n",
    "classifier_1.add(Dropout(0.2))\n",
    "# Output Layer\n",
    "classifier_1.add(Dense(number_of_diseases, activation='softmax', kernel_initializer='random_normal'))\n",
    "classifier_1.add(Dropout(0.2))\n",
    "classifier_1.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "classifier_1.load_weights('saved_models/weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDSRSLA\n"
     ]
    }
   ],
   "source": [
    "def diagnosis(answers,classifier):\n",
    "    predicted_value = classifier.predict(answers)\n",
    "    return diagnosis_raw[np.argmax(predicted_value)]\n",
    "\n",
    "print(diagnosis(X_test[:1],classifier_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 99.50%\n",
      "acc: 99.49%\n",
      "acc: 99.47%\n",
      "acc: 99.73%\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "acc: 99.72%\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "acc: 99.72%\n",
      "99.76% (+/- 0.21%)\n"
     ]
    }
   ],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "X = dataset\n",
    "Y = pd.read_pickle('data/diagnosis.pkl')\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    # We have to use raw data before split and then on hot encode\n",
    "    encoder.fit(Y[train])\n",
    "    encoded_Y = encoder.transform(Y[train])\n",
    "    dummy_y_train = np_utils.to_categorical(encoded_Y)\n",
    "    \n",
    "    encoder.fit(Y[test])\n",
    "    encoded_Y = encoder.transform(Y[test])\n",
    "    dummy_y_test = np_utils.to_categorical(encoded_Y)\n",
    "     \n",
    "    #Model\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal', input_dim=len(dataset.columns)))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'),)\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(number_of_diseases, activation='softmax', kernel_initializer='random_normal'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    \n",
    "    # Fit & evaluate\n",
    "    classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    classifier.fit(X.iloc[train], dummy_y_train, validation_split=0.25, epochs=100, batch_size=10, verbose=0)\n",
    "    scores = classifier.evaluate(X.iloc[test], dummy_y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucp",
   "language": "python",
   "name": "ucp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
